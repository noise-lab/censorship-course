---
marp: true
theme: default
paginate: true
---

# Digital Services Act (DSA)
## EU's Framework for Platform Transparency

Week 8 - Censorship & Transparency

---

# Background

- **Enacted**: 2022, fully applicable October 2023
- **Scope**: All digital services in EU (27 member states)
- **Goal**: Make platforms accountable for content moderation
- **Key shift**: From voluntary transparency → mandatory requirements

---

# What Problem Does DSA Solve?

**Before DSA:**
- Platforms self-report (or don't)
- No standardization
- Missing key details:
  - Who requested takedown?
  - Automated vs. manual decision?
  - Legal grounds for removal?
- No independent verification

---

# Very Large Online Platforms (VLOPs)

**Definition**: 45+ million monthly active users in EU

**Examples:**
- Meta (Facebook, Instagram)
- Google (YouTube, Search)
- TikTok, X (Twitter)
- Amazon, Apple App Store

**Why 45M?** ~10% of EU population (≈450M people)

---

# VLOP Requirements

1. **Statements of Reasons** for every moderation action
2. Structured, machine-readable format
3. Must disclose:
   - Who requested (government, user, automated)
   - Legal basis
   - Appeal rights
4. Data access for researchers
5. Risk assessments

---

# Statements of Reasons: What's Included

- **Decision type**: Removal, demotion, restriction, etc.
- **Content category**: Hate speech, misinformation, illegal content
- **Automated or manual** review
- **Legal ground**: Specific law or ToS clause
- **Requester**: Government order, user report, proactive detection

---

# DSA Transparency Database

- Centralized repository of all Statements of Reasons
- Publicly searchable
- Allows researcher analysis across platforms
- https://transparency.dsa.ec.europa.eu/

**First of its kind**: Standardized, mandatory, verifiable

---

# History & Timeline

- **2020**: Proposed by European Commission
- **2022**: Adopted by EU Parliament
- **Feb 2024**: VLOPs must comply
- **Oct 2024**: Full implementation for all platforms

Builds on GDPR model: EU regulation → global impact?

---

# Why Not Smaller Platforms?

**Student Question**: Why exempt platforms <45M users?

**Answer**:
- Regulatory burden vs. impact tradeoff
- Small platforms lack resources for compliance
- Focus enforcement where most users affected
- Phased approach (may expand later)

---

# Key Questions from Students

1. Does DSA solve all transparency gaps?
2. How are Statements of Reasons implemented in practice?
3. Are there equivalents outside the EU?
4. What are implementation challenges?

---

# Does DSA Solve Everything?

**Progress:**
✅ Standardized disclosure
✅ Automated vs. manual distinction
✅ Legal grounds required
✅ Researcher access

**Still missing:**
❌ Shadow bans / downranking
❌ Economic censorship (demonetization)
❌ Algorithm transparency
❌ Recommendation system details

---

# Implementation Challenges

- **Volume**: Millions of decisions daily
- **Timeliness**: Real-time moderation vs. documentation
- **Quality**: Generic vs. specific reasons
- **Gaming**: Platforms may provide minimal compliance
- **Enforcement**: EU must actually penalize non-compliance

---

# Global Equivalents?

**Short answer**: Not really

- **Australia**: Online Safety Act (different focus)
- **UK**: Online Safety Bill (less prescriptive)
- **US**: No federal requirement (First Amendment issues)
- **California**: Limited transparency laws

**DSA is unique** in scope and detail

---

# California/Brussels Effect?

**Will platforms implement DSA globally?**

**Possible**:
- Easier to have one global standard
- Avoid fragmenting systems

**But**:
- May limit DSA to EU users only
- Evidence is mixed so far
- Student question: Has this actually happened?

---

# Researcher Access

**New**: DSA grants researchers data access

**Benefits**:
- Independent verification of platform claims
- Study patterns across platforms
- Identify systemic issues

**Concerns**:
- Privacy of users whose content was moderated
- Platform vulnerability exposure
- Who qualifies as "researcher"?

---

# Open Questions

1. How much detail without compromising privacy?
2. Can transparency reports be trusted even with DSA?
3. Will enforcement actually happen?
4. Does transparency change platform behavior?
5. Will this model spread globally?

---

# Discussion

**The fundamental tension:**

Greater transparency ↔ Platform operational security

How do we verify accountability without exposing systems to gaming?

